{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Activation, Dropout, Dense, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('/mnt/ufs18/home-053/hejaseba/IMDBDataset.csv')\n",
    "\n",
    "data['review'] = data['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
    "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
    "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
    "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
    "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
    "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data):\n",
    "  data['review without stopwords'] = data['review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
    "  return data\n",
    "\n",
    "def remove_tags(string):\n",
    "    result = re.sub('<.*?>','',string)\n",
    "    return result\n",
    "    \n",
    "data_without_stopwords = remove_stopwords(data)\n",
    "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
    "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = data_without_stopwords['clean_review']\n",
    "\n",
    "reviews_list = []\n",
    "for i in range(len(reviews)):\n",
    "  reviews_list.append(reviews[i])\n",
    " \n",
    "sentiment = data_without_stopwords['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, sentiment)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,Y_train, Y_test = train_test_split(reviews_list, y, test_size=0.2, random_state = 45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=105124)\n",
    "tokenizer.fit_on_texts(X_train+X_test)\n",
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vector(glove_vec):\n",
    "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
    "    words = set()\n",
    "    word_to_vec_map = {}\n",
    "    for line in f:\n",
    "      w_line = line.split()\n",
    "      curr_word = w_line[0]\n",
    "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
    "\n",
    "\n",
    "\n",
    "  return word_to_vec_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_vec_map = read_glove_vector('/mnt/ufs18/home-053/hejaseba/glove.6B.300d.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(words_to_index)\n",
    "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
    "\n",
    "emb_matrix = np.zeros((vocab_len, embed_vector_len)) # (95419,50)\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "  embedding_vector = word_to_vec_map.get(word)\n",
    "  if embedding_vector is not None  and index!=105124:\n",
    "    emb_matrix[index, :] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re, pprint, string\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "emb_ = torch.tensor(emb_matrix,requires_grad=True,dtype=torch.float64,device=\"cuda\") # ,requires_grad=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = []\n",
    "max_ = 1505 # then try 600 \n",
    "for i in range(0,len(X_train)):\n",
    "    seq_ = word_tokenize(X_train[i])\n",
    "    X_train_2.append([])\n",
    "    for k in range(0,len(seq_)):\n",
    "        ind_ = 0\n",
    "        if(seq_[k] in words_to_index.keys()):\n",
    "            ind_ = words_to_index[seq_[k]]\n",
    "            if(ind_>=105124):\n",
    "                ind_ = 0\n",
    "        X_train_2[i].append(ind_)\n",
    "    \n",
    "    if(len(X_train_2[i])<max_):\n",
    "        \n",
    "        for j in range(0,max_-len(X_train_2[i])):\n",
    "            X_train_2[i].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2 = []\n",
    "max_ = 1505 # then try 600 \n",
    "for i in range(0,len(X_test)):\n",
    "    seq_ = word_tokenize(X_test[i])\n",
    "    X_test_2.append([])\n",
    "    for k in range(0,len(seq_)):\n",
    "        ind_ = 0\n",
    "        if(seq_[k] in words_to_index.keys()):\n",
    "            ind_ = words_to_index[seq_[k]]\n",
    "            if(ind_>=105124):\n",
    "                ind_ = 0\n",
    "        X_test_2[i].append(ind_)\n",
    "    \n",
    "    if(len(X_test_2[i])<max_):\n",
    "        \n",
    "        for j in range(0,max_-len(X_test_2[i])):\n",
    "            X_test_2[i].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ =torch.tensor(Y_test,device=\"cuda\")\n",
    "y_ = torch.reshape(y_,(1,10000)).float() # X\n",
    "\n",
    "y_ = y_[0]\n",
    "\n",
    "\n",
    "y =torch.tensor(Y_train,device=\"cuda\")\n",
    "y = torch.reshape(y,(1,40000)).float() # X\n",
    "y = y[0]\n",
    "\n",
    "W1 = torch.normal(0,0.01, size=(300,512),requires_grad=True,device=\"cuda\")\n",
    "U1 = torch.normal(0,0.01, size=(1,512),requires_grad=True,device=\"cuda\")\n",
    "bw1 = torch.zeros(size=(1,512),requires_grad=True,device=\"cuda\")\n",
    "\n",
    "\n",
    "W2 = torch.normal(0,0.01, size=(512,512),requires_grad=True,device=\"cuda\")\n",
    "U2 = torch.normal(0,0.01, size=(1,512),requires_grad=True,device=\"cuda\")\n",
    "bw2 = torch.zeros(size=(1,512),requires_grad=True,device=\"cuda\")\n",
    "\n",
    "W3 = torch.normal(0,0.01, size=(512,512),requires_grad=True,device=\"cuda\")\n",
    "U3 = torch.normal(0,0.01, size=(1,512),requires_grad=True,device=\"cuda\")\n",
    "bw3 = torch.zeros(size=(1,512),requires_grad=True,device=\"cuda\")\n",
    "\n",
    "\n",
    "W4 = torch.normal(0,0.01, size=(512,512),requires_grad=True,device=\"cuda\")\n",
    "U4 = torch.normal(0,0.01, size=(1,512),requires_grad=True,device=\"cuda\")\n",
    "bw4 = torch.zeros(size=(1,512),requires_grad=True,device=\"cuda\")\n",
    "\n",
    "\n",
    "\n",
    "V = torch.normal(0,0.01, size=(512,2),requires_grad=True,device=\"cuda\") # 3000 * 1\n",
    "bv = torch.zeros(size=(1,2),requires_grad=True,device=\"cuda\")\n",
    "\n",
    "params = [W1,U1,bw1,W2,U2,bw2,W3,U3,bw3,W4,U4,bw4,V,bv,emb_] #,emb_]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_ = nn.ReLU().cuda()\n",
    "\n",
    "tan_ = nn.Tanh().cuda()\n",
    "m = nn.Sigmoid().cuda()\n",
    "s_ = nn.Softmax(dim=1) # (1,2)\n",
    "\n",
    "def models(X):     \n",
    "        h1 = torch.zeros(size=(1,512),device=\"cuda\")\n",
    "        h2 = torch.zeros(size=(1,512),device=\"cuda\")\n",
    "        h3 = torch.zeros(size=(1,512),device=\"cuda\")\n",
    "        h4 = torch.zeros(size=(1,512),device=\"cuda\")\n",
    "\n",
    "        for i in range(0,len(X[0])): \n",
    "              ind = [X[s_][i] for s_ in range(0,1) ]                \n",
    "              if(0 not in ind):\n",
    "\n",
    "                    \n",
    "                h1 = ( emb_[ind].float() @ W1) + bw1 + (h1 * U1)\n",
    "                h1 = r_(h1)\n",
    "                \n",
    "                h2 = ( h1 @ W2) + bw2 + (h2 * U2)\n",
    "                h2 = r_(h2)\n",
    "\n",
    "                h3 = ( h2 @ W3) + bw3 + (h3 * U3)\n",
    "                h3 = r_(h3)       \n",
    "                \n",
    "                h4 = ( h3 @ W4) + bw4 + (h4 * U4)\n",
    "                h4 = r_(h4)   \n",
    "  \n",
    "                \n",
    "        y = h4 @ V + bv\n",
    "        \n",
    "        \n",
    "        y = s_(y)\n",
    "        return y\n",
    "    \n",
    "    \n",
    "\n",
    "def cross_entropy(y_hat,y):\n",
    "    to_ =  -torch.log(y_hat[range(len(y_hat)),y]+1e-8)\n",
    "    to_ =  to_.sum(0,keepdim=True)\n",
    "    to_ = to_ / 1.0\n",
    "    return to_ + (((r_(torch.abs(U1) -1))**2).sum())/2 + (((r_(torch.abs(U2) -1))**2).sum())/2 + (((r_(torch.abs(U3) -1))**2).sum())/2 + (((r_(torch.abs(U4) -1))**2).sum())/2\n",
    "    \n",
    "\n",
    "trainer = torch.optim.Adam(params, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X,pass_=1):  \n",
    "        h1 = torch.zeros(size=(1,512),device=\"cuda\")\n",
    "        h2 = torch.zeros(size=(1,512),device=\"cuda\")\n",
    "        h3 = torch.zeros(size=(1,512),device=\"cuda\")\n",
    "        h4 = torch.zeros(size=(1,512),device=\"cuda\")\n",
    "\n",
    "        if(pass_==11):\n",
    "            len_=350\n",
    "        else:\n",
    "            len_ = len(X)\n",
    "            \n",
    "        \n",
    "        for i in range(0,len_): # maybe take average\n",
    "              ind = X[i]\n",
    "              if(ind!=0):\n",
    "\n",
    "                h1 = ( emb_[ind].float() @ W1) + bw1 + (h1 * U1)\n",
    "                h1 = r_(h1)\n",
    "                \n",
    "                h2 = ( h1 @ W2) + bw2 + (h2 * U2)\n",
    "                h2 = r_(h2)\n",
    "                \n",
    "                h3 = ( h2 @ W3) + bw3 + (h3 * U3)\n",
    "                h3 = r_(h3)\n",
    "                \n",
    "                h4 = ( h3 @ W4) + bw4 + (h4 * U4)\n",
    "                h4 = r_(h4)\n",
    "                \n",
    "        y = h4 @ V + bv\n",
    "        \n",
    "        \n",
    "        y = s_(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "validation accuracy  0.9066666666666666\n",
      "1\n",
      "validation accuracy  0.91\n",
      "2\n",
      "validation accuracy  0.9133333333333333\n",
      "3\n",
      "validation accuracy  0.9033333333333333\n",
      "4\n",
      "validation accuracy  0.9133333333333333\n",
      "5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a1f6b9634651>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0ml_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#grad_clipping(params, 1.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "import math\n",
    "for k in range(0,10000):\n",
    "    if(k>13):\n",
    "        trainer = torch.optim.Adam(params, lr=0.0001)\n",
    "    print(k)\n",
    "    for i in range(0,1000):\n",
    "            #print(i)\n",
    "            j= random.randrange(1,39990,1)\n",
    "            y_hat = models(X_train_2[j:j+1])\n",
    "            l_ = cross_entropy(y_hat, y[j:j+1].long()) \n",
    "            \n",
    "            #l_ = cross_entropy(y_hat.t(), y[j].long())            \n",
    "            trainer.zero_grad()\n",
    "            \n",
    "            l_.backward()\n",
    "            \n",
    "            #grad_clipping(params, 1.0)\n",
    "            trainer.step()\n",
    "\n",
    "            #print(emb_.grad[0:10])\n",
    "    # Predicting on Training data\n",
    "    '''\n",
    "    preds = []\n",
    "    for i in range(0,300):\n",
    "       #print(i)\n",
    "       y_hat = test(X_train_2[i])\n",
    "       preds.append(torch.argmax(y_hat).cpu())\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(\"training accuracy \", accuracy_score(y[0:300].cpu().numpy(), preds))\n",
    "    '''\n",
    "    preds = []\n",
    "    for i in range(0,300):\n",
    "       #print(i)\n",
    "       y_hat = models(X_test_2[i:i+1])\n",
    "       preds.append(torch.argmax(y_hat).cpu())\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    print(\"validation accuracy \", accuracy_score(y_[0:300].cpu().numpy(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy  0.93\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for i in range(300,10000):\n",
    "       #print(i)\n",
    "       y_hat = models(X_test_2[i:i+1])\n",
    "       preds.append(torch.argmax(y_hat).cpu())\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"test accuracy \", accuracy_score(y_[300:10000].cpu().numpy(), preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
